{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0658a37",
   "metadata": {},
   "source": [
    "Reducción de la dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e754ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuración de rutas ===\n",
    "TRAIN_PATH = \"../data/dataset/X_train_scaled.csv\"  \n",
    "TEST_PATH  = \"../data/dataset/X_test_scaled.csv\"   \n",
    "OUT_DIR    = \"../data/output\"                          \n",
    "TARGET_VARIANCE = 0.95                             # 95% por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a34192fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d791e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6819, 6008)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv(TRAIN_PATH)\n",
    "X_test  = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f70e8fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import silhouette_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7087b39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Missing Values en X_train ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>genres.1</th>\n",
       "      <td>6819</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>6819</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genres</th>\n",
       "      <td>6819</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title.1</th>\n",
       "      <td>6819</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hog_1168</th>\n",
       "      <td>4728</td>\n",
       "      <td>69.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zernike_15.2</th>\n",
       "      <td>1766</td>\n",
       "      <td>25.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zernike_14.2</th>\n",
       "      <td>1766</td>\n",
       "      <td>25.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zernike_13.2</th>\n",
       "      <td>1766</td>\n",
       "      <td>25.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zernike_12.2</th>\n",
       "      <td>1766</td>\n",
       "      <td>25.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zernike_11.2</th>\n",
       "      <td>1766</td>\n",
       "      <td>25.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5968 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missing Values  Missing Percentage\n",
       "genres.1                6819              100.00\n",
       "title                   6819              100.00\n",
       "genres                  6819              100.00\n",
       "title.1                 6819              100.00\n",
       "hog_1168                4728               69.34\n",
       "...                      ...                 ...\n",
       "zernike_15.2            1766               25.90\n",
       "zernike_14.2            1766               25.90\n",
       "zernike_13.2            1766               25.90\n",
       "zernike_12.2            1766               25.90\n",
       "zernike_11.2            1766               25.90\n",
       "\n",
       "[5968 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Missing Values en X_test ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>title.1</th>\n",
       "      <td>2923</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>2923</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hog_1319.1</th>\n",
       "      <td>786</td>\n",
       "      <td>26.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hog_1733.2</th>\n",
       "      <td>786</td>\n",
       "      <td>26.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hog_1335.1</th>\n",
       "      <td>786</td>\n",
       "      <td>26.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_2</th>\n",
       "      <td>726</td>\n",
       "      <td>24.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_1</th>\n",
       "      <td>726</td>\n",
       "      <td>24.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_6</th>\n",
       "      <td>726</td>\n",
       "      <td>24.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_24</th>\n",
       "      <td>726</td>\n",
       "      <td>24.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_23</th>\n",
       "      <td>726</td>\n",
       "      <td>24.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5945 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Missing Values  Missing Percentage\n",
       "title.1               2923              100.00\n",
       "title                 2923              100.00\n",
       "hog_1319.1             786               26.89\n",
       "hog_1733.2             786               26.89\n",
       "hog_1335.1             786               26.89\n",
       "...                    ...                 ...\n",
       "color_2                726               24.84\n",
       "color_1                726               24.84\n",
       "color_6                726               24.84\n",
       "color_24               726               24.84\n",
       "color_23               726               24.84\n",
       "\n",
       "[5945 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de valores faltantes:\n",
      "X_train: 16,513,352\n",
      "X_test: 4,560,844\n"
     ]
    }
   ],
   "source": [
    "def analyze_missing_values(df):\n",
    "    # Calcular valores faltantes\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "    \n",
    "    # Crear DataFrame con el análisis\n",
    "    missing_info = pd.DataFrame({\n",
    "        'Missing Values': missing_values,\n",
    "        'Missing Percentage': missing_percentage.round(2)\n",
    "    })\n",
    "    \n",
    "    # Ordenar por cantidad de valores faltantes (descendente)\n",
    "    missing_info = missing_info.sort_values('Missing Values', ascending=False)\n",
    "    \n",
    "    # Mostrar solo columnas con al menos un valor faltante\n",
    "    return missing_info[missing_info['Missing Values'] > 0]\n",
    "\n",
    "# Analizar tanto el conjunto de entrenamiento como el de prueba\n",
    "print(\"=== Missing Values en X_train ===\")\n",
    "display(analyze_missing_values(X_train))\n",
    "\n",
    "print(\"\\n=== Missing Values en X_test ===\")\n",
    "display(analyze_missing_values(X_test))\n",
    "\n",
    "# Mostrar el total de valores faltantes\n",
    "print(\"\\nTotal de valores faltantes:\")\n",
    "print(f\"X_train: {X_train.isnull().sum().sum():,}\")\n",
    "print(f\"X_test: {X_test.isnull().sum().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b838bd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones originales:\n",
      "X_train: (6819, 6008)\n",
      "X_test: (2923, 5966)\n",
      "\n",
      "Dimensiones después de eliminar filas con NA:\n",
      "X_train: (0, 6008)\n",
      "X_test: (0, 5966)\n",
      "\n",
      "Filas eliminadas:\n",
      "X_train: 6,819 filas\n",
      "X_test: 2,923 filas\n"
     ]
    }
   ],
   "source": [
    "# Guardar dimensiones originales\n",
    "print(\"Dimensiones originales:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "\n",
    "# Eliminar filas con valores faltantes\n",
    "X_train_clean = X_train.dropna(axis=0, how='any')\n",
    "X_test_clean = X_test.dropna(axis=0, how='any')\n",
    "\n",
    "# Mostrar dimensiones después de la limpieza\n",
    "print(\"\\nDimensiones después de eliminar filas con NA:\")\n",
    "print(f\"X_train: {X_train_clean.shape}\")\n",
    "print(f\"X_test: {X_test_clean.shape}\")\n",
    "\n",
    "# Mostrar cantidad de filas eliminadas\n",
    "print(\"\\nFilas eliminadas:\")\n",
    "print(f\"X_train: {X_train.shape[0] - X_train_clean.shape[0]:,} filas\")\n",
    "print(f\"X_test: {X_test.shape[0] - X_test_clean.shape[0]:,} filas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2e7512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes → train: (6819, 6008)  test: (2923, 5966)\n"
     ]
    }
   ],
   "source": [
    "    # Limpieza por si el índice está guardado como columna\n",
    "for df in (X_train, X_test):\n",
    "    if df.columns[0].lower() in (\"unnamed: 0\", \"index\", \"\"):\n",
    "        df.drop(df.columns[0], axis=1, inplace=True)\n",
    "    df[:] = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "print(\"Shapes → train:\", X_train.shape, \" test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6297938d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m pca_full = PCA()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mpca_full\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m explained_var = pca_full.explained_variance_ratio_\n\u001b[32m      4\u001b[39m cum_explained = np.cumsum(explained_var)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laura\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1466\u001b[39m     estimator._validate_params()\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1469\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1470\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1471\u001b[39m     )\n\u001b[32m   1472\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laura\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:448\u001b[39m, in \u001b[36mPCA.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    430\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    432\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[32m    433\u001b[39m \n\u001b[32m    434\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    446\u001b[39m \u001b[33;03m        Returns the instance itself.\u001b[39;00m\n\u001b[32m    447\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m448\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laura\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:511\u001b[39m, in \u001b[36mPCA._fit\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    501\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPCA with svd_solver=\u001b[39m\u001b[33m'\u001b[39m\u001b[33marpack\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is not supported for Array API inputs.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    503\u001b[39m     )\n\u001b[32m    505\u001b[39m \u001b[38;5;66;03m# Validate the data, without ever forcing a copy as any solver that\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# supports sparse input data and the `covariance_eigh` solver are\u001b[39;00m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# written in a way to avoid the need for any inplace modification of\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;66;03m# the input data contrary to the other solvers.\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[38;5;66;03m# The copy will happen\u001b[39;00m\n\u001b[32m    510\u001b[39m \u001b[38;5;66;03m# later, only if needed, once the solver negotiation below is done.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[38;5;28mself\u001b[39m._fit_svd_solver = \u001b[38;5;28mself\u001b[39m.svd_solver\n\u001b[32m    520\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit_svd_solver == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laura\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:633\u001b[39m, in \u001b[36mBaseEstimator._validate_data\u001b[39m\u001b[34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[39m\n\u001b[32m    631\u001b[39m         out = X, y\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m    635\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laura\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1058\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1059\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1060\u001b[39m         % (array.ndim, estimator_name)\n\u001b[32m   1061\u001b[39m     )\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1066\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1072\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1073\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laura\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laura\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    156\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    158\u001b[39m     msg_err += (\n\u001b[32m    159\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    171\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "pca_full = PCA()\n",
    "pca_full.fit(X_train.values)\n",
    "explained_var = pca_full.explained_variance_ratio_\n",
    "cum_explained = np.cumsum(explained_var)\n",
    "\n",
    "# Selección de k (mínimo con ≥ TARGET_VARIANCE)\n",
    "k = int(np.searchsorted(cum_explained, TARGET_VARIANCE) + 1)\n",
    "print(f\"Componentes totales: {len(explained_var)} | k seleccionado (≥{int(TARGET_VARIANCE*100)}%): {k}\")\n",
    "print(f\"Varianza acumulada con k={k}: {cum_explained[k-1]:.4f}\")\n",
    "\n",
    "# Tabla de varianza explicada\n",
    "var_table = pd.DataFrame({\n",
    "    'component': np.arange(1, len(explained_var)+1),\n",
    "    'explained_variance_ratio': explained_var,\n",
    "    'cumulative_variance_ratio': cum_explained\n",
    "})\n",
    "display(var_table.head(25))\n",
    "\n",
    "# Gráficos\n",
    "plt.figure()\n",
    "plt.plot(np.arange(1, len(explained_var)+1), explained_var, marker='o')\n",
    "plt.xlabel('Componente principal')\n",
    "plt.ylabel('Varianza explicada (ratio)')\n",
    "plt.title('Scree plot - PCA (todas las componentes)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(1, len(cum_explained)+1), cum_explained, marker='o')\n",
    "plt.axhline(y=TARGET_VARIANCE, linestyle='--')\n",
    "plt.axvline(x=k, linestyle='--')\n",
    "plt.xlabel('Número de componentes')\n",
    "plt.ylabel('Varianza explicada acumulada')\n",
    "plt.title(f'Varianza acumulada - PCA (k={k})')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b729369a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_train: (6819, 19) Z_test: (2923, 19)\n"
     ]
    }
   ],
   "source": [
    "# Refit con k componentes y transformación de train/test \n",
    "pca_k = PCA(n_components=k, svd_solver='full', random_state=0)\n",
    "pca_k.fit(X_train.values)\n",
    "Z_train = pca_k.transform(X_train.values)\n",
    "Z_test  = pca_k.transform(X_test.values)\n",
    "print(\"Z_train:\", Z_train.shape, \"Z_test:\", Z_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e86166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado:\n",
      "- ..\\data\\output\\X_train_pca_k19.csv\n",
      "- ..\\data\\output\\X_test_pca_k19.csv\n",
      "- ..\\data\\output\\pca_variance_report.csv\n",
      "- ..\\data\\output\\pca_metadata.json\n",
      "- ..\\data\\output\\pca_model_k19.pkl\n"
     ]
    }
   ],
   "source": [
    "# === Guardado de resultados y artefactos ===\n",
    "out_dir = Path(OUT_DIR)\n",
    "train_out = out_dir / f\"X_train_pca_k{k}.csv\"\n",
    "test_out  = out_dir / f\"X_test_pca_k{k}.csv\"\n",
    "var_out   = out_dir / \"pca_variance_report.csv\"\n",
    "meta_out  = out_dir / \"pca_metadata.json\"\n",
    "model_out = out_dir / f\"pca_model_k{k}.pkl\"\n",
    "\n",
    "pd.DataFrame(Z_train).to_csv(train_out, index=False)\n",
    "pd.DataFrame(Z_test).to_csv(test_out, index=False)\n",
    "var_table.to_csv(var_out, index=False)\n",
    "\n",
    "meta = {\n",
    "    \"train_path\": TRAIN_PATH,\n",
    "    \"test_path\": TEST_PATH,\n",
    "    \"train_shape\": tuple(X_train.shape),\n",
    "    \"test_shape\": tuple(X_test.shape),\n",
    "    \"n_features\": int(X_train.shape[1]),\n",
    "    \"k_selected\": int(k),\n",
    "    \"target_variance\": float(TARGET_VARIANCE),\n",
    "    \"achieved_variance\": float(np.cumsum(pca_k.explained_variance_ratio_)[-1])\n",
    "}\n",
    "with open(meta_out, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "with open(model_out, \"wb\") as f:\n",
    "    pickle.dump(pca_k, f)\n",
    "\n",
    "print(\"Guardado:\")\n",
    "print(\"-\", train_out)\n",
    "print(\"-\", test_out)\n",
    "print(\"-\", var_out)\n",
    "print(\"-\", meta_out)\n",
    "print(\"-\", model_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
