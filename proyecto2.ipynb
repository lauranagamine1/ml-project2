{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "O5oEGFWkcmV_"
      },
      "outputs": [],
      "source": [
        "import os, re\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b5Q41caZk5o"
      },
      "source": [
        "# EXPLORACI√ìN DE DATOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "b5rprB4cYBXb"
      },
      "outputs": [],
      "source": [
        "def extract_year(title: str):\n",
        "    if not isinstance(title, str):\n",
        "        return np.nan\n",
        "    m = re.search(r\"\\((\\d{4})\\)$\", title.strip())\n",
        "    return int(m.group(1)) if m else np.nan\n",
        "\n",
        "def split_genres(s: str):\n",
        "    if pd.isna(s) or s == \"\":\n",
        "        return [\"(no genres listed)\"]\n",
        "    return s.split(\"|\")\n",
        "\n",
        "def describe_df(name, df: pd.DataFrame, head_n=5):\n",
        "    print(f\"\\n===== {name} =====\")\n",
        "    print(\"shape:\", df.shape)\n",
        "    print(\"columnas:\", list(df.columns))\n",
        "    print(f\"\\n{head_n} primeras filas:\")\n",
        "    print(df.head(head_n))\n",
        "    print(\"\\nNulos por columna:\")\n",
        "    print(df.isna().sum())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amKMVIVlhVy7"
      },
      "source": [
        "##Cargamos la data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9dIuRXcJhYOZ"
      },
      "outputs": [],
      "source": [
        "TRAIN = \"movies_train.csv\"\n",
        "TEST  = \"movies_test.csv\"\n",
        "ML_MOVIES = \"/content/movies.csv\"\n",
        "\n",
        "if not os.path.exists(TRAIN): raise FileNotFoundError(TRAIN)\n",
        "if not os.path.exists(TEST):  raise FileNotFoundError(TEST)\n",
        "if not os.path.exists(ML_MOVIES): raise FileNotFoundError(ML_MOVIES)\n",
        "\n",
        "train = pd.read_csv(TRAIN)\n",
        "test  = pd.read_csv(TEST)\n",
        "ml_movies = pd.read_csv(ML_MOVIES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VcGgBr7hj1o"
      },
      "source": [
        "##Revisamos los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGASpSu4hwxw"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqYltnGfd7c9",
        "outputId": "2a81fed6-7f7b-4cea-db18-9ad2c6fcc986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== TRAIN =====\n",
            "shape: (6819, 23)\n",
            "columnas: ['movieId', 'title', 'genres', '(no genres listed)', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'IMAX', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
            "\n",
            "5 primeras filas:\n",
            "   movieId                             title          genres  \\\n",
            "0      619                         Ed (1996)          Comedy   \n",
            "1    33826                Saint Ralph (2004)    Comedy|Drama   \n",
            "2     1298       Pink Floyd: The Wall (1982)   Drama|Musical   \n",
            "3   140289              Men & Chicken (2015)    Comedy|Drama   \n",
            "4     3064  Poison Ivy: New Seduction (1997)  Drama|Thriller   \n",
            "\n",
            "   (no genres listed)  Action  Adventure  Animation  Children  Comedy  Crime  \\\n",
            "0                   0       0          0          0         0       1      0   \n",
            "1                   0       0          0          0         0       1      0   \n",
            "2                   0       0          0          0         0       0      0   \n",
            "3                   0       0          0          0         0       1      0   \n",
            "4                   0       0          0          0         0       0      0   \n",
            "\n",
            "   ...  Film-Noir  Horror  IMAX  Musical  Mystery  Romance  Sci-Fi  Thriller  \\\n",
            "0  ...          0       0     0        0        0        0       0         0   \n",
            "1  ...          0       0     0        0        0        0       0         0   \n",
            "2  ...          0       0     0        1        0        0       0         0   \n",
            "3  ...          0       0     0        0        0        0       0         0   \n",
            "4  ...          0       0     0        0        0        0       0         1   \n",
            "\n",
            "   War  Western  \n",
            "0    0        0  \n",
            "1    0        0  \n",
            "2    0        0  \n",
            "3    0        0  \n",
            "4    0        0  \n",
            "\n",
            "[5 rows x 23 columns]\n",
            "\n",
            "Nulos por columna:\n",
            "movieId               0\n",
            "title                 0\n",
            "genres                0\n",
            "(no genres listed)    0\n",
            "Action                0\n",
            "Adventure             0\n",
            "Animation             0\n",
            "Children              0\n",
            "Comedy                0\n",
            "Crime                 0\n",
            "Documentary           0\n",
            "Drama                 0\n",
            "Fantasy               0\n",
            "Film-Noir             0\n",
            "Horror                0\n",
            "IMAX                  0\n",
            "Musical               0\n",
            "Mystery               0\n",
            "Romance               0\n",
            "Sci-Fi                0\n",
            "Thriller              0\n",
            "War                   0\n",
            "Western               0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "describe_df(\"TRAIN\", train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CtjDnXyh2yK"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIZt4VSjeOaN",
        "outputId": "711d105d-0650-47af-fd5c-85db9c422c18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== TEST =====\n",
            "shape: (2923, 2)\n",
            "columnas: ['movieId', 'title']\n",
            "\n",
            "5 primeras filas:\n",
            "   movieId                                   title\n",
            "0    45635       Notorious Bettie Page, The (2005)\n",
            "1     1373  Star Trek V: The Final Frontier (1989)\n",
            "2     7325                  Starsky & Hutch (2004)\n",
            "3      389              Colonel Chabert, Le (1994)\n",
            "4     8920                Country Girl, The (1954)\n",
            "\n",
            "Nulos por columna:\n",
            "movieId    0\n",
            "title      0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "describe_df(\"TEST\", test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwQG97F0h9wq"
      },
      "source": [
        "### Movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rDACRcJeSEn",
        "outputId": "26473c33-55dc-4f8b-eae2-ad3bfb1d1a4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== MOVIELENS movies.csv =====\n",
            "shape: (5, 3)\n",
            "columnas: ['movieId', 'title', 'genres']\n",
            "\n",
            "5 primeras filas:\n",
            "       movieId                             title  \\\n",
            "4884      4990  Jimmy Neutron: Boy Genius (2001)   \n",
            "22971   116698              Dead Men Tell (1941)   \n",
            "26257   125517                   The D.I. (1957)   \n",
            "57524   196541         Makar - Pathfinder (1984)   \n",
            "39134   156511              Feudin' Fools (1952)   \n",
            "\n",
            "                                    genres  \n",
            "4884   Adventure|Animation|Children|Comedy  \n",
            "22971  Comedy|Crime|Drama|Mystery|Thriller  \n",
            "26257                                Drama  \n",
            "57524                   Adventure|Children  \n",
            "39134                               Comedy  \n",
            "\n",
            "Nulos por columna:\n",
            "movieId    0\n",
            "title      0\n",
            "genres     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "describe_df(\"MOVIELENS movies.csv\", ml_movies.sample(min(5, len(ml_movies)), random_state=42))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eqjkPW-i9JC"
      },
      "source": [
        "### Cruce de movieId entre Train/Test y MovieLens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3FGPOzAb0Mc",
        "outputId": "f716f1ff-56e2-43bc-b8a9-19d602b0dcc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total movieId requeridos: 9742\n",
            "Encontrados en movies.csv: 9454\n"
          ]
        }
      ],
      "source": [
        "needed_ids = set(train[\"movieId\"].tolist() + test[\"movieId\"].tolist())\n",
        "movies_sub = ml_movies[ml_movies[\"movieId\"].isin(needed_ids)].copy()\n",
        "print(f\"\\nTotal movieId requeridos: {len(needed_ids)}\")\n",
        "print(\"Encontrados en movies.csv:\", movies_sub.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-W17jr_jDs0"
      },
      "source": [
        "### Explorar g√©neros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTIzu2I5b04Z",
        "outputId": "2eb90473-cc62-44ec-a689-21749acefcc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 15 g√©neros (conteo en train+test):\n",
            "  Drama           -> 4276\n",
            "  Comedy          -> 3655\n",
            "  Thriller        -> 1851\n",
            "  Action          -> 1736\n",
            "  Romance         -> 1569\n",
            "  Adventure       -> 1196\n",
            "  Crime           -> 1173\n",
            "  Horror          -> 941\n",
            "  Sci-Fi          -> 917\n",
            "  Fantasy         -> 738\n",
            "  Children        -> 626\n",
            "  Mystery         -> 558\n",
            "  Animation       -> 527\n",
            "  Documentary     -> 421\n",
            "  War             -> 378\n",
            "\n",
            "Pel√≠culas sin g√©nero: 33\n"
          ]
        }
      ],
      "source": [
        "movies_sub[\"genres\"] = movies_sub[\"genres\"].fillna(\"(no genres listed)\")\n",
        "all_genres = []\n",
        "for s in movies_sub[\"genres\"]:\n",
        "    all_genres.extend(split_genres(s))\n",
        "\n",
        "genre_counts = Counter(all_genres)\n",
        "print(\"\\nTop 15 g√©neros (conteo en train+test):\")\n",
        "for g, c in genre_counts.most_common(15):\n",
        "    print(f\"  {g:15s} -> {c}\")\n",
        "\n",
        "no_genres = movies_sub[movies_sub[\"genres\"].eq(\"(no genres listed)\")].shape[0]\n",
        "print(\"\\nPel√≠culas sin g√©nero:\", no_genres)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX_hSwdDjJiQ"
      },
      "source": [
        "### Explorar a√±os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3Fkk83ib3UY",
        "outputId": "5cb2d49e-c8b0-407a-9f1a-3a9d00497633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "A√±o (resumen):\n",
            "count    9442.000000\n",
            "mean     1994.391231\n",
            "std        18.683605\n",
            "min      1902.000000\n",
            "25%      1987.000000\n",
            "50%      1999.000000\n",
            "75%      2008.000000\n",
            "max      2018.000000\n",
            "Name: year, dtype: float64\n",
            "A√±os faltantes: 12\n"
          ]
        }
      ],
      "source": [
        "movies_sub[\"year\"] = movies_sub[\"title\"].apply(extract_year)\n",
        "print(\"\\nA√±o (resumen):\")\n",
        "print(movies_sub[\"year\"].describe())\n",
        "\n",
        "missing_year = movies_sub[\"year\"].isna().sum()\n",
        "print(\"A√±os faltantes:\", missing_year)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op5HGbnzjNf6"
      },
      "source": [
        "### Datos duplicados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AqW9r6Ib6Ld",
        "outputId": "68febf06-cf7e-4cfa-ecf5-b21e12e4fbdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Duplicados por movieId: 0\n"
          ]
        }
      ],
      "source": [
        "dups = movies_sub[movies_sub.duplicated(\"movieId\", keep=False)]\n",
        "print(\"\\nDuplicados por movieId:\", dups.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv4lOdTgcNpR"
      },
      "source": [
        "## LIMPIEZA Y CONSTRUCCION DE FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bLYRf6jCc48J"
      },
      "outputs": [],
      "source": [
        "def build_features_from_movies(movies_df: pd.DataFrame):\n",
        "    df = movies_df.copy()\n",
        "    df[\"genres\"] = df[\"genres\"].fillna(\"(no genres listed)\")\n",
        "    genre_set = set()\n",
        "    for s in df[\"genres\"]:\n",
        "        genre_set.update(s.split(\"|\"))\n",
        "    genre_list = sorted(list(genre_set))\n",
        "\n",
        "    for g in genre_list:\n",
        "        df[g] = df[\"genres\"].apply(lambda s: 1 if g in s.split(\"|\") else 0).astype(int)\n",
        "\n",
        "    df[\"year\"] = df[\"title\"].apply(extract_year)\n",
        "    df[\"year\"] = df[\"year\"].fillna(df[\"year\"].median())\n",
        "    feat_cols = genre_list + [\"year\"]\n",
        "    return df, feat_cols\n",
        "\n",
        "def main():\n",
        "    needed_ids = set(train[\"movieId\"].tolist() + test[\"movieId\"].tolist())\n",
        "    movies_sub = ml_movies[ml_movies[\"movieId\"].isin(needed_ids)].copy()\n",
        "    movies_feats, feat_cols = build_features_from_movies(movies_sub)\n",
        "\n",
        "    # IDs disponibles\n",
        "    id_to_row = movies_feats.set_index(\"movieId\")\n",
        "    available_ids = set(id_to_row.index)\n",
        "\n",
        "    def get_safe_features(df_ids):\n",
        "        feats = []\n",
        "        for mid in df_ids:\n",
        "            if mid in available_ids:\n",
        "                feats.append(id_to_row.loc[mid, feat_cols].values)\n",
        "            else:\n",
        "                empty = [0] * (len(feat_cols) - 1) + [movies_feats[\"year\"].median()]\n",
        "                feats.append(empty)\n",
        "        return pd.DataFrame(feats, columns=feat_cols)\n",
        "\n",
        "    X_train_raw = get_safe_features(train[\"movieId\"].values)\n",
        "    X_test_raw  = get_safe_features(test[\"movieId\"].values)\n",
        "\n",
        "    # Escalado\n",
        "    scaler = StandardScaler()\n",
        "    X_all = pd.concat([X_train_raw, X_test_raw], axis=0).reset_index(drop=True)\n",
        "    X_all_scaled = pd.DataFrame(scaler.fit_transform(X_all), columns=feat_cols)\n",
        "\n",
        "    X_train_scaled = X_all_scaled.iloc[:len(X_train_raw)].reset_index(drop=True)\n",
        "    X_test_scaled  = X_all_scaled.iloc[len(X_train_raw):].reset_index(drop=True)\n",
        "\n",
        "    os.makedirs(\"outputs\", exist_ok=True)\n",
        "    X_train_scaled.to_csv(\"outputs/X_train_scaled.csv\", index=False)\n",
        "    X_test_scaled.to_csv(\"outputs/X_test_scaled.csv\", index=False)\n",
        "\n",
        "    print(\"\\nFeatures generados correctamente.\")\n",
        "    print(f\"Train shape: {X_train_scaled.shape}\")\n",
        "    print(f\"Test shape: {X_test_scaled.shape}\")\n",
        "    print(f\"Columnas: {feat_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-24jwQUHda_m",
        "outputId": "255b7d79-e8b0-4088-f5d8-9b4553fde31f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Features generados correctamente.\n",
            "Train shape: (6819, 21)\n",
            "Test shape: (2923, 21)\n",
            "Columnas: ['(no genres listed)', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'IMAX', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western', 'year']\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Obtenci√≥n de los posters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Rutas\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m movielens_links = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m\"\u001b[39m\u001b[33mlinks.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m moviegenre = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mMovieGenre.csv\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mlatin1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMovieLens links.csv ‚Üí\u001b[39m\u001b[33m\"\u001b[39m, movielens_links.shape)\n",
            "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "# Rutas\n",
        "movielens_links = pd.read_csv(\"links.csv\")\n",
        "moviegenre = pd.read_csv(\"MovieGenre.csv\", encoding=\"latin1\")\n",
        "print(\"MovieLens links.csv ‚Üí\", movielens_links.shape)\n",
        "print(\"MovieGenre.csv ‚Üí\", moviegenre.shape)\n",
        "\n",
        "# Cruce (inner join)\n",
        "merged = pd.merge(movielens_links, moviegenre, on=\"imdbId\", how=\"inner\")\n",
        "merged_needed = merged[merged[\"movieId\"].isin(needed_ids)]\n",
        "\n",
        "print(f\"üé¨ Pel√≠culas requeridas (train+test): {len(needed_ids)}\")\n",
        "print(f\"üì∏ Pel√≠culas con p√≥ster disponible: {len(merged_needed)}\")\n",
        "print(f\"‚úÖ Cobertura de p√≥sters: {len(merged_needed)/len(needed_ids)*100:.2f}%\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Descarga de posters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "\n",
        "POSTER_DIR = \"posters\"\n",
        "os.makedirs(POSTER_DIR, exist_ok=True)\n",
        "\n",
        "def download_poster(row):\n",
        "    movie_id = row[\"movieId\"]\n",
        "    url = row[\"Poster\"]\n",
        "    path = os.path.join(POSTER_DIR, f\"{movie_id}.jpg\")\n",
        "\n",
        "    if os.path.exists(path):\n",
        "        return \"skip\"\n",
        "\n",
        "    if pd.isna(url) or not isinstance(url, str) or not url.startswith(\"http\"):\n",
        "        return \"invalid\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, timeout=5)\n",
        "        if response.status_code == 200:\n",
        "            with open(path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            return \"ok\"\n",
        "        else:\n",
        "            return f\"fail({response.status_code})\"\n",
        "    except Exception:\n",
        "        return \"error\"\n",
        "\n",
        "subset = merged_needed    # Solo train + test\n",
        "\n",
        "max_threads = 20  \n",
        "status_counter = {\"ok\": 0, \"skip\": 0, \"fail\": 0, \"error\": 0, \"invalid\": 0}\n",
        "\n",
        "print(f\"Iniciando descarga de {len(subset)} p√≥sters con {max_threads} hilos...\\n\")\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
        "    futures = [executor.submit(download_poster, row) for _, row in subset.iterrows()]\n",
        "    for i, future in enumerate(tqdm(as_completed(futures), total=len(futures), desc=\"Descargando\")):\n",
        "        result = future.result()\n",
        "        if result.startswith(\"fail\"):\n",
        "            status_counter[\"fail\"] += 1\n",
        "        elif result == \"error\":\n",
        "            status_counter[\"error\"] += 1\n",
        "        elif result == \"invalid\":\n",
        "            status_counter[\"invalid\"] += 1\n",
        "        elif result == \"skip\":\n",
        "            status_counter[\"skip\"] += 1\n",
        "        else:\n",
        "            status_counter[\"ok\"] += 1\n",
        "\n",
        "print(\"\\nDescarga completa.\")\n",
        "print(f\"Nuevas descargas: {status_counter['ok']}\")\n",
        "print(f\"Omitidas (ya exist√≠an): {status_counter['skip']}\")\n",
        "print(f\"Fallidas: {status_counter['fail']}\")\n",
        "print(f\"Errores: {status_counter['error']}\")\n",
        "print(f\"URLs inv√°lidas: {status_counter['invalid']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extracci√≥n de Caracter√≠sticas Visuales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Histogramas de color (RGB + HSV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "OUTPUT_DIR = \"outputs\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def extract_color_histograms(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        return [np.nan]*192\n",
        "    img = cv2.resize(img, (128, 128))\n",
        "    # --- RGB ---\n",
        "    hist_r = cv2.calcHist([img], [0], None, [32], [0,256])\n",
        "    hist_g = cv2.calcHist([img], [1], None, [32], [0,256])\n",
        "    hist_b = cv2.calcHist([img], [2], None, [32], [0,256])\n",
        "    # --- HSV ---\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    hist_h = cv2.calcHist([hsv], [0], None, [32], [0,180])\n",
        "    hist_s = cv2.calcHist([hsv], [1], None, [32], [0,256])\n",
        "    hist_v = cv2.calcHist([hsv], [2], None, [32], [0,256])\n",
        "    \n",
        "    # Normalizar y concatenar\n",
        "    features = np.concatenate([hist_r, hist_g, hist_b, hist_h, hist_s, hist_v]).flatten()\n",
        "    features = features / np.sum(features)\n",
        "    return features.tolist()\n",
        "\n",
        "movie_ids = subset[\"movieId\"].values\n",
        "color_features = []\n",
        "\n",
        "for movie_id in tqdm(movie_ids, desc=\"Extrayendo RGB+HSV\", total=len(movie_ids)):\n",
        "    path = os.path.join(POSTER_DIR, f\"{movie_id}.jpg\")\n",
        "    feats = extract_color_histograms(path)\n",
        "    color_features.append([movie_id] + feats)\n",
        "\n",
        "cols = [\"movieId\"] + [f\"color_{i}\" for i in range(len(color_features[0])-1)]\n",
        "df_color = pd.DataFrame(color_features, columns=cols)\n",
        "df_color.to_csv(os.path.join(OUTPUT_DIR, \"poster_color_features.csv\"), index=False)\n",
        "\n",
        "print(\"Histograms RGB+HSV guardados en poster_color_features.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HOG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from skimage import color, io, transform\n",
        "from skimage.feature import hog\n",
        "\n",
        "def extract_hog_features(image_path):\n",
        "    try:\n",
        "        img = io.imread(image_path)\n",
        "        img_gray = color.rgb2gray(img)\n",
        "    except Exception:\n",
        "        # Imagen corrupta\n",
        "        return None\n",
        "    img_gray = transform.resize(img_gray, (128, 128))\n",
        "\n",
        "    hog_feats = hog(\n",
        "        img_gray,\n",
        "        pixels_per_cell=(16, 16),\n",
        "        cells_per_block=(2, 2),\n",
        "        orientations=9,\n",
        "        feature_vector=True\n",
        "    )\n",
        "    return hog_feats\n",
        "\n",
        "hog_features = []\n",
        "dim_example = None\n",
        "\n",
        "for movie_id in tqdm(movie_ids, desc=\"Extrayendo HOG\", total=len(movie_ids)):\n",
        "    path = os.path.join(POSTER_DIR, f\"{movie_id}.jpg\")\n",
        "    feats = extract_hog_features(path)\n",
        "    if feats is not None:\n",
        "        if dim_example is None:\n",
        "            dim_example = len(feats)\n",
        "        hog_features.append([movie_id] + feats.tolist())\n",
        "    else:\n",
        "        hog_features.append([movie_id] + [np.nan] * (dim_example or 0))\n",
        "if dim_example is not None:\n",
        "    cols = [\"movieId\"] + [f\"hog_{i}\" for i in range(dim_example)]\n",
        "    df_hog = pd.DataFrame(hog_features, columns=cols)\n",
        "    df_hog.to_csv(os.path.join(OUTPUT_DIR, \"poster_hog_features.csv\"), index=False)\n",
        "    print(f\"HOG guardados en {OUTPUT_DIR}/poster_hog_features.csv\")\n",
        "    print(f\"Dimensi√≥n del vector HOG: {dim_example}\")\n",
        "else:\n",
        "    print(\"No se pudo extraer ning√∫n HOG v√°lido.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Zernike"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mahotas\n",
        "\n",
        "def extract_zernike(image_path, radius=64, degree=8):\n",
        "    try:\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            return None\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    except Exception:\n",
        "        return None\n",
        "    gray = cv2.resize(gray, (128, 128))\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    zernike = mahotas.features.zernike_moments(thresh, radius=radius, degree=degree)\n",
        "    return zernike\n",
        "\n",
        "zernike_features = []\n",
        "dim_example = None\n",
        "\n",
        "for movie_id in tqdm(movie_ids, desc=\"Extrayendo Zernike\", total=len(movie_ids)):\n",
        "    path = os.path.join(POSTER_DIR, f\"{movie_id}.jpg\")\n",
        "    feats = extract_zernike(path)\n",
        "    if feats is not None:\n",
        "        if dim_example is None:\n",
        "            dim_example = len(feats)\n",
        "        zernike_features.append([movie_id] + feats.tolist())\n",
        "    else:\n",
        "        zernike_features.append([movie_id] + [np.nan] * (dim_example or 0))\n",
        "\n",
        "# === GUARDAR RESULTADOS ===\n",
        "if dim_example is not None:\n",
        "    cols = [\"movieId\"] + [f\"zernike_{i}\" for i in range(dim_example)]\n",
        "    df_zernike = pd.DataFrame(zernike_features, columns=cols)\n",
        "    df_zernike.to_csv(os.path.join(OUTPUT_DIR, \"poster_zernike_features.csv\"), index=False)\n",
        "    print(f\"Momentos Zernike guardados en {OUTPUT_DIR}/poster_zernike_features.csv\")\n",
        "    print(f\"Dimensi√≥n del vector Zernike: {dim_example}\")\n",
        "else:\n",
        "    print(\"No se pudo extraer ning√∫n descriptor Zernike v√°lido.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combinar las feactures con el x_test_scaled.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "COLOR_PATH   = os.path.join(OUTPUT_DIR, \"poster_color_features.csv\")\n",
        "HOG_PATH     = os.path.join(OUTPUT_DIR, \"poster_hog_features.csv\")\n",
        "ZERNIKE_PATH = os.path.join(OUTPUT_DIR, \"poster_zernike_features.csv\")\n",
        "X_TRAIN_PATH = os.path.join(OUTPUT_DIR, \"X_train_scaled.csv\")\n",
        "X_TEST_PATH  = os.path.join(OUTPUT_DIR, \"X_test_scaled.csv\")\n",
        "\n",
        "df_color   = pd.read_csv(COLOR_PATH)\n",
        "df_hog     = pd.read_csv(HOG_PATH)\n",
        "df_zernike = pd.read_csv(ZERNIKE_PATH)\n",
        "x_train = pd.read_csv(X_TRAIN_PATH)\n",
        "x_test  = pd.read_csv(X_TEST_PATH)\n",
        "\n",
        "df_visual = df_color.merge(df_hog, on=\"movieId\", how=\"outer\")\n",
        "df_visual = df_visual.merge(df_zernike, on=\"movieId\", how=\"outer\")\n",
        "\n",
        "train_full = train.merge(df_visual, on=\"movieId\", how=\"left\")\n",
        "test_full  = test.merge(df_visual, on=\"movieId\", how=\"left\")\n",
        "\n",
        "x_train_full = pd.concat([x_train, train_full.drop(columns=[\"movieId\"])], axis=1)\n",
        "x_test_full  = pd.concat([x_test,  test_full.drop(columns=[\"movieId\"])], axis=1)\n",
        "\n",
        "x_train_full.to_csv(X_TRAIN_PATH, index=False)\n",
        "x_test_full.to_csv(X_TEST_PATH, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
